# **StaGeoMod2022 - week 3 -[Multiple Linear Regressions (GLMs) - ]**

## Objectives of this week.

1. Explore your dataset to avoid common statistical problems when performing a simple/multiple linear regression.
2.	Implement as simple/multiple linear regression in `R`.  
3.	Discriminate between raw and standardised regressions coefficients. 
4.	Determine the fit of a linear regression and establish how good a model is.  
5.	Reduce a model to the minimum adequate number of predictors using a stepwise procedure.   

## Multiple Linear Regressions (GLMs) in a nutshell

Regression analysis is the statistical method you use when both the response variable and the explanatory variable are continuous variables (i.e. real numbers with decimal places – things like heights, weights, volumes, or temperatures). Perhaps the easiest way of knowing when regression is the appropriate analysis is to see that a scatterplot is the appropriate graphic (in contrast to analysis of variance, say, where it would have been a box-and-whisker plot or a bar chart).

**The essence of regression analysis is using sample data to estimate parameter values and their standard errors.**

Linear regression is one of the most basic statistical models out there, its results can be interpreted by almost everyone, and it has been around since the 19th century. This is precisely what makes linear regression so popular. It’s simple, and it has survived for hundreds of years. Even though it is not as sophisticated as other algorithms it is the algorithm most used by data scientists in 2016 and 2017. It’s even predicted it’s still going to be the used in year 2118!
